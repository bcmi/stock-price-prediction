{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- This is one of the submitted solutions to Artificial Intelligence Final Project\n",
    "- Team Member: Zhi-jun Liu, Meng-qi Cao\n",
    "\n",
    "This notebook contains the Linear Model solution (private : 0.00147 | public : 0.00151).\n",
    "\n",
    "The submittion is from an **ensemble** of similar linear model results, the hyper parameter of which is not saved at the time. (Anyway, we won't bother to find them since this model is much inferior to the CNN-RNN model, and you shall not care about this one.) \n",
    "\n",
    "The ensembled result is (private : 0.00143 | public : 0.00151)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- python 3.7\n",
    "- Pytorch == 1.0\n",
    "- Pandas == 0.23.4\n",
    "- Numpy == 1.15.4\n",
    "- Tqdm == 4.28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:13:17.000800Z",
     "start_time": "2018-12-28T21:13:16.997160Z"
    }
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T20:52:58.341572Z",
     "start_time": "2018-12-28T20:52:58.313206Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "device = torch.device(\"cpu\")\n",
    "default_cpu_tensor_type = torch.FloatTensor\n",
    "torch.set_default_tensor_type(default_cpu_tensor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T20:53:00.746735Z",
     "start_time": "2018-12-28T20:52:58.433271Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSVReader:\n",
    "    dataitems = [\"MidPrice\", \"LastPrice\", \"Volume\", \"BidPrice1\", \"BidVolume1\", \"AskPrice1\", \"AskVolume1\"]\n",
    "    def __init__(self, training_set=\"./train_data.csv\", testing_set=\"./test_data.csv\"):\n",
    "        self.Train = pd.read_csv(training_set,\n",
    "                                 index_col=\"Date\",\n",
    "                                 usecols=[\n",
    "                                     \"Date\", \"Time\",\n",
    "                                     \"MidPrice\", \"LastPrice\",\n",
    "                                     \"Volume\", \"BidPrice1\",\n",
    "                                     \"BidVolume1\", \"AskPrice1\",\n",
    "                                     \"AskVolume1\"\n",
    "                                 ])\n",
    "\n",
    "        self.Test = pd.read_csv(testing_set,\n",
    "                                index_col=\"Date\",\n",
    "                                usecols=[\n",
    "                                    \"Date\", \"Time\",\n",
    "                                    \"MidPrice\", \"LastPrice\",\n",
    "                                    \"Volume\", \"BidPrice1\",\n",
    "                                    \"BidVolume1\", \"AskPrice1\",\n",
    "                                    \"AskVolume1\"\n",
    "                                ])\n",
    "\n",
    "\n",
    "        self.Train = self.Train.sort_index()\n",
    "        self.Test = self.Test.sort_index()\n",
    "        def hour(s):\n",
    "            q = [float(i) for i in s.split(\":\")]\n",
    "            return q[0] + q[1] / 60\n",
    "\n",
    "        self.Train[\"Hour\"] = self.Train[\"Time\"].map(hour)\n",
    "\n",
    "        self.Test[\"Hour\"] = self.Test[\"Time\"].map(hour)\n",
    "\n",
    "        TimeStampCount = self.Train[\"Time\"].groupby(\"Date\").count()\n",
    "        TimeStampCount = TimeStampCount.sort_values()\n",
    "\n",
    "        self.TrainDates = self.Train.index.unique().tolist()\n",
    "        self.DangerousDates = TimeStampCount[TimeStampCount > 5000].index.tolist()\n",
    "        self.FilteredDates = [date for date in self.TrainDates if date not in self.DangerousDates]\n",
    "\n",
    "        self.TrainSet = {}\n",
    "\n",
    "        self.AM = self.Train[self.Train[\"Hour\"] < 11.70]\n",
    "        self.PM = self.Train[self.Train[\"Hour\"] > 12.70]\n",
    "\n",
    "        for date in self.FilteredDates:\n",
    "            self.TrainSet[f\"{date}|AM\"] = self.AM.loc[date]\n",
    "            self.TrainSet[f\"{date}|PM\"] = self.PM.loc[date]\n",
    "\n",
    "        # Splitting Testing Set\n",
    "        self.TestingSet = []\n",
    "\n",
    "        for begin in range(0, len(self.Test), 10):\n",
    "            self.TestingSet.append(self.Test.iloc[begin: begin + 10])\n",
    "\n",
    "    def training_dates(self):\n",
    "        \"\"\"\n",
    "        Returning all training set dates\n",
    "        \"\"\"\n",
    "        return self.FilteredDates\n",
    "\n",
    "    def get_training_numpy(self, idx):\n",
    "        \"\"\"\n",
    "        Returning training set at idx, also the am / pm / date infomation trailing it.\n",
    "        [T, Feature]\n",
    "        \"\"\"\n",
    "        key = list(self.TrainSet.keys())[idx]\n",
    "        pandadb = self.TrainSet[key][self.dataitems]\n",
    "        return key, pandadb.values\n",
    "\n",
    "    def get_testing_numpy(self, idx):\n",
    "        \"\"\"\n",
    "        Returning testing set at idx, also the am / pm / date infomation trailing it.\n",
    "        [T, Feature]\n",
    "        \"\"\"\n",
    "        pandadb = self.TestingSet[idx][self.dataitems]\n",
    "        return pandadb.values\n",
    "\n",
    "    def training_count(self):\n",
    "        \"\"\"\n",
    "        Returning the count of all available sub training set, including morning and afternoon\n",
    "        \"\"\"\n",
    "        return len(self.TrainSet)\n",
    "\n",
    "    def testing_count(self):\n",
    "        \"\"\"\n",
    "        Returning the count of all testing instance\n",
    "        \"\"\"\n",
    "        return len(self.TestingSet)\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    Q = torch.arange(0, 30, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    def __init__(self, csvreader=CSVReader()):\n",
    "        \"\"\"\n",
    "        This class reads from a csvreader and can provide infinite\n",
    "        instance of training data.\n",
    "        It supports batched training generation of training data.\n",
    "        It loads data to GPU / CPU immediately when initialization\n",
    "        The data manipulation is completely on GPU\n",
    "        \"\"\"\n",
    "        self.Train = []\n",
    "        self.Test = []\n",
    "\n",
    "        self.reader = csvreader\n",
    "        for idx in range(self.reader.training_count()):\n",
    "            time, npdata = self.reader.get_training_numpy(idx)\n",
    "            self.Train.append(torch.from_numpy(npdata).contiguous().to(device=device, dtype=torch.float32))\n",
    "\n",
    "        for idx in range(self.reader.testing_count()):\n",
    "            npdata = self.reader.get_testing_numpy(idx)\n",
    "            self.Test.append(torch.from_numpy(npdata).contiguous().to(device=device, dtype=torch.float32))\n",
    "\n",
    "        self.valid_idx = []\n",
    "        self.train_idx = [_ for _ in range(0, len(self.Train))]\n",
    "        self.set_validation_set([30, 31])\n",
    "\n",
    "    def sample_batch(self, batch_size=32, source=\"train\", full=False):\n",
    "        if source == \"train\":\n",
    "            choice = np.random.choice(self.train_idx)\n",
    "        else:\n",
    "            choice = np.random.choice(self.valid_idx)\n",
    "\n",
    "        L = len(self.Train[choice])\n",
    "        IDX = torch.randint(0, L - 30, (batch_size,))\n",
    "        A = self.Train[choice]\n",
    "        Q = self.Q\n",
    "        P = IDX.unsqueeze(1)\n",
    "        W = A[P + Q]\n",
    "        M = torch.mean(W[:, 10:, 0], dim=1)\n",
    "        if full:\n",
    "            return W[:, :30, :], M\n",
    "        else:\n",
    "            return W[:, :10, :], M\n",
    "\n",
    "    def sample_train(self, batch_size=32, full=False):\n",
    "        return self.sample_batch(batch_size, full=full)\n",
    "\n",
    "    def sample_valid(self, batch_size=32, full=False):\n",
    "        return self.sample_batch(batch_size, source=\"valid\", full=full)\n",
    "\n",
    "    def get_test(self):\n",
    "        # Returns all 1000 testing samples\n",
    "        return torch.stack(self.Test, dim=0)\n",
    "\n",
    "    def set_validation_set(self, lst):\n",
    "        self.valid_idx = lst\n",
    "        self.train_idx.clear()\n",
    "        for idx in range(0, len(self.Train)):\n",
    "            if idx not in lst:\n",
    "                self.train_idx.append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T20:53:33.775432Z",
     "start_time": "2018-12-28T20:53:33.762171Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, loader):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        if issubclass(type(self.model), torch.nn.Module):\n",
    "            self.optim = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
    "\n",
    "    def train(self, round=20000, batch_size=128, lr=0.0001, validation=(10, 17), cp=0.1, penalty=0.1):\n",
    "        valid = 1\n",
    "        global_valid = 1\n",
    "        assert issubclass(type(self.model), torch.nn.Module), \"Can only train NN Models\"\n",
    "        self.optim.lr = lr\n",
    "        bar = tqdm_notebook(iterable=range(round), desc=\"Training\")\n",
    "        self.loader.set_validation_set(validation)\n",
    "        for i in bar:\n",
    "            Trainset, Target = self.loader.sample_train(batch_size)\n",
    "            self.optim.zero_grad()\n",
    "            Estimation = self.model(Trainset)\n",
    "            Loss = self.rmse_loss(Target, Estimation) + self.model.penalty() * penalty\n",
    "            bar.set_postfix(loss=f\"{Loss.detach().cpu():0.6f}\", valid=valid, gbvalid=global_valid)\n",
    "            Loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), cp)\n",
    "            self.optim.step()\n",
    "            if i % 1024 == 1:\n",
    "                valid = self.validate()\n",
    "                global_valid = self.validate_all()\n",
    "                self.loader.set_validation_set(validation)\n",
    "\n",
    "        return Loss\n",
    "\n",
    "    def validate(self, valid_size=256):\n",
    "        Validset, Target = self.loader.sample_valid(valid_size)\n",
    "        Estimation = self.model(Validset)\n",
    "        Loss = self.rmse_loss(Target, Estimation)\n",
    "        Loss = Loss.detach().cpu().item()\n",
    "        return Loss\n",
    "\n",
    "    def validate_all(self):\n",
    "        p = []\n",
    "        for i in range(self.loader.reader.training_count()):\n",
    "            self.loader.set_validation_set([i])\n",
    "            p.append(self.validate(valid_size=1024))\n",
    "\n",
    "        return torch.mean(torch.tensor(p)).detach().cpu().item()\n",
    "\n",
    "    def rmse_loss(self, target, estimate):\n",
    "        return torch.sqrt(self.loss(target, estimate))\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the valid data\n",
    "        Output the result to submission.csv\n",
    "        \"\"\"\n",
    "        Testset = self.loader.get_test()\n",
    "        print(Testset.shape)\n",
    "        Estimation = self.model(Testset)\n",
    "        self.printing(Estimation)\n",
    "        print(Estimation.shape)\n",
    "\n",
    "    def printing(self, result, begin=143):\n",
    "        t = pd.DataFrame(result[begin - 1:].unsqueeze(1).detach().cpu().numpy(), columns=[\"midprice\"],\n",
    "                         index=np.arange(begin, result.size(0) + 1))\n",
    "        t.index.name = 'caseid'\n",
    "        t.to_csv(f\"submission{np.random.randint(100)}.csv\")\n",
    "        print(\"Printing Over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T20:53:34.947162Z",
     "start_time": "2018-12-28T20:53:34.302531Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T20:53:34.994787Z",
     "start_time": "2018-12-28T20:53:34.984913Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_transformer(data):\n",
    "    data = data.detach()\n",
    "    # Volume, Log and Normalized\n",
    "    data[:, 1:, 2] -= data[:, :-1, 2]\n",
    "    data[:, 0, 2] = 0.0\n",
    "    data[:, :, 2] = torch.log(data[:, :, 2] + 1) / 19\n",
    "    \n",
    "    # BidVolume1(4) and AskVolume1(6)\n",
    "    data[:, :, 4] = torch.log(data[:, :, 4] + 1) / 14\n",
    "    data[:, :, 6] = torch.log(data[:, :, 6] + 1) / 14\n",
    "    \n",
    "    # Dumping LastPrice(1), BidPrice(3), AskPrice(5)\n",
    "    data = torch.cat([data[:, :, :1], data[:, :, 2:3], data[:, :, 4:5], data[:, :, 6:]], dim=-1)\n",
    "    # Shifting Price to Centering the last element\n",
    "    ankor = data[:, -1, 0].clone()\n",
    "    data[:, :, 0] = data[:, :, 0] - data[:, -1, 0].unsqueeze(1)\n",
    "    return data, ankor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:13:52.271555Z",
     "start_time": "2018-12-28T21:13:52.264653Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearModel(Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.la = torch.nn.Linear(40, 50)\n",
    "        self.lb = torch.nn.Linear(50, 50)\n",
    "        self.lc = torch.nn.Linear(50, 1)\n",
    "\n",
    "    def penalty(self):\n",
    "        return 0.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, y = log_transformer(x)\n",
    "        x = x.view(-1, 40)\n",
    "        x = self.la(x)\n",
    "        r = x\n",
    "        x = x.relu()\n",
    "        x = self.lb(x) + r\n",
    "        x = x.relu()\n",
    "        x = self.lc(x)\n",
    "        x = x.view(-1)\n",
    "        return x * 0.005 + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:05:55.400891Z",
     "start_time": "2018-12-28T21:05:55.396272Z"
    }
   },
   "outputs": [],
   "source": [
    "lineartrainer = Trainer(LinearModel(), loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:06:21.288785Z",
     "start_time": "2018-12-28T21:06:13.216407Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5472ab8475d5465d8072efb6f6dd8351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=2000, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0013, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineartrainer.train(batch_size=32, cp=10, lr=0.0000001, round=2000, penalty=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:06:22.602185Z",
     "start_time": "2018-12-28T21:06:22.586997Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 10, 7])\n",
      "Printing Over\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "lineartrainer.test()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
